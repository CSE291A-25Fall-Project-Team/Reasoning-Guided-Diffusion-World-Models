{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f29cae1bfc6d455c8c94a87e409fac58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c828ad63678445dc9439a6a28d69395f",
              "IPY_MODEL_4b727ca3260d4f98a654bfecd7da0f1f",
              "IPY_MODEL_63a50c58040b45cdbb5b3ec12b0fa2f0"
            ],
            "layout": "IPY_MODEL_2fba4505192344c8a5062b01cbe0ed68"
          }
        },
        "c828ad63678445dc9439a6a28d69395f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f61586b60cd450081217ff6d39d20fb",
            "placeholder": "​",
            "style": "IPY_MODEL_360014197e2c495cad8299f30d16b8be",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4b727ca3260d4f98a654bfecd7da0f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186f19c2f7db4b3b938787fb96ab2e94",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b624a2339a89460e94101bbe08359ebe",
            "value": 3
          }
        },
        "63a50c58040b45cdbb5b3ec12b0fa2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3ec0ad9089443ea3bf4ad282aced5e",
            "placeholder": "​",
            "style": "IPY_MODEL_accc77ecc3824ea384d0e6e3db68f7c2",
            "value": " 3/3 [00:03&lt;00:00,  1.11s/it]"
          }
        },
        "2fba4505192344c8a5062b01cbe0ed68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f61586b60cd450081217ff6d39d20fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360014197e2c495cad8299f30d16b8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "186f19c2f7db4b3b938787fb96ab2e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b624a2339a89460e94101bbe08359ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a3ec0ad9089443ea3bf4ad282aced5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "accc77ecc3824ea384d0e6e3db68f7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install av\n",
        "! pip install bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD-ZksocKfcE",
        "outputId": "cf0ca679-2da5-42b1-d9ef-767f6cfb52c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (16.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYXA8TPUYKGc",
        "outputId": "d87b8632-1c5d-412d-df83-f0f32e13d2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using CUDA GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import av\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    LlavaNextVideoProcessor,\n",
        "    LlavaNextVideoForConditionalGeneration\n",
        ")\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def get_best_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"✅ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"✅ Using Apple Silicon GPU (MPS backend)\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"⚠️ No GPU found — using CPU\")\n",
        "    return device\n",
        "\n",
        "device = get_best_device()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "HF_TOKEN = \"\" #add your hugging face token here\n",
        "login(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "54LtfLWQbqLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configuration ---\n",
        "MODEL_ID = \"llava-hf/LLaVA-NeXT-Video-7B-hf\"\n",
        "#substitute VIDEO_PATH with diffusion genereated video\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/cse291a/project/llavaCritic/IMG_1813.mp4\"\n",
        "QUESTION_PROMPT = \"what did this robot do\"\n",
        "# The conversation template format for LLaVA-NeXT\n",
        "PROMPT = f\"USER: <video>\\n{QUESTION_PROMPT}ASSISTANT:\""
      ],
      "metadata": {
        "id": "GGeAx-cIYOYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWK5I-slikOb",
        "outputId": "96b28d78-b52d-471a-c254-264ffaa91c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import av\n",
        "import torch\n",
        "import numpy as np\n",
        "from huggingface_hub import hf_hub_download\n",
        "from transformers import LlavaNextVideoProcessor, LlavaNextVideoForConditionalGeneration\n",
        "\n",
        "model_id = MODEL_ID\n",
        "\n",
        "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        ").to(0)\n",
        "\n",
        "processor = LlavaNextVideoProcessor.from_pretrained(model_id)\n",
        "\n",
        "def read_video_pyav(container, indices):\n",
        "    '''\n",
        "    Decode the video with PyAV decoder.\n",
        "    Args:\n",
        "        container (`av.container.input.InputContainer`): PyAV container.\n",
        "        indices (`List[int]`): List of frame indices to decode.\n",
        "    Returns:\n",
        "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    frames = []\n",
        "    container.seek(0)\n",
        "    start_index = indices[0]\n",
        "    end_index = indices[-1]\n",
        "    for i, frame in enumerate(container.decode(video=0)):\n",
        "        if i > end_index:\n",
        "            break\n",
        "        if i >= start_index and i in indices:\n",
        "            frames.append(frame)\n",
        "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
        "\n",
        "\n",
        "# define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
        "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\", \"video\")\n",
        "conversation = [\n",
        "    {\n",
        "\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": QUESTION_PROMPT},\n",
        "            {\"type\": \"video\"},\n",
        "            ],\n",
        "    },\n",
        "]\n",
        "\n",
        "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
        "\n",
        "# video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename=\"sample_demo_1.mp4\", repo_type=\"dataset\")\n",
        "container = av.open(VIDEO_PATH)\n",
        "\n",
        "# sample uniformly 8 frames from the video, can sample more for longer videos\n",
        "total_frames = container.streams.video[0].frames\n",
        "indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n",
        "clip = read_video_pyav(container, indices)\n",
        "inputs_video = processor(text=prompt, videos=clip, padding=True, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "output = model.generate(**inputs_video, max_new_tokens=100, do_sample=False)\n",
        "llava_candidate_answer = processor.decode(output[0][2:], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f29cae1bfc6d455c8c94a87e409fac58",
            "c828ad63678445dc9439a6a28d69395f",
            "4b727ca3260d4f98a654bfecd7da0f1f",
            "63a50c58040b45cdbb5b3ec12b0fa2f0",
            "2fba4505192344c8a5062b01cbe0ed68",
            "7f61586b60cd450081217ff6d39d20fb",
            "360014197e2c495cad8299f30d16b8be",
            "186f19c2f7db4b3b938787fb96ab2e94",
            "b624a2339a89460e94101bbe08359ebe",
            "2a3ec0ad9089443ea3bf4ad282aced5e",
            "accc77ecc3824ea384d0e6e3db68f7c2"
          ]
        },
        "id": "A7czAAhcKwUk",
        "outputId": "dedbd700-d7f6-4f4d-9908-753564bbf2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f29cae1bfc6d455c8c94a87e409fac58"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- LLaVA-NeXT-Video Result ---\")\n",
        "print(f\"Question: {QUESTION_PROMPT}\")\n",
        "print(f\"Answer: **{llava_candidate_answer}**\")\n",
        "print(\"-----------------------------\\n\")\n",
        "\n",
        "# --- 5. BERTScore Part Configuration ---\n",
        "# *** REPLACE WITH GOAL ***\n",
        "\n",
        "GROUND_TRUTH_REFERENCE = \"The robot arm used its gripper to successfully pick up the yellow cube from the left side of the table and place it on the red platform.\"\n",
        "\n",
        "from bert_score import score\n",
        "\n",
        "candidate = llava_candidate_answer\n",
        "reference = GROUND_TRUTH_REFERENCE\n",
        "\n",
        "# --- Compute BERTScore ---\n",
        "P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=False)\n",
        "\n",
        "print(\"--- BERTScore Evaluation ---\")\n",
        "print(f\"Reference: {reference}\")\n",
        "print(f\"Candidate: {candidate}\")\n",
        "print(f\"BERTScore P: {P.item():.4f}\")\n",
        "print(f\"BERTScore R: {R.item():.4f}\")\n",
        "print(f\"BERTScore F1: **{F1.item():.4f}** (Main Metric)\")\n",
        "print(\"----------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkJVMO-mYWS2",
        "outputId": "cd294103-3611-44c9-d203-2de6b3f33028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LLaVA-NeXT-Video Result ---\n",
            "Question: what did this robot do\n",
            "Answer: **ER: \n",
            "what did this robot do ASSISTANT: The robot in the image appears to be an industrial robotic arm, likely used for tasks such as assembling, welding, or handling objects in a factory setting. It is equipped with a gripper at the end of its arm, which is used to pick up and manipulate objects. The robot is currently in a position where it seems to be either picking up or placing down an object, possibly a part or a component, as indicated by the gripper's position**\n",
            "-----------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BERTScore Evaluation ---\n",
            "Reference: The robot arm used its gripper to successfully pick up the yellow cube from the left side of the table and place it on the red platform.\n",
            "Candidate: ER: \n",
            "what did this robot do ASSISTANT: The robot in the image appears to be an industrial robotic arm, likely used for tasks such as assembling, welding, or handling objects in a factory setting. It is equipped with a gripper at the end of its arm, which is used to pick up and manipulate objects. The robot is currently in a position where it seems to be either picking up or placing down an object, possibly a part or a component, as indicated by the gripper's position\n",
            "BERTScore P: 0.8419\n",
            "BERTScore R: 0.8723\n",
            "BERTScore F1: **0.8568** (Main Metric)\n",
            "----------------------------\n"
          ]
        }
      ]
    }
  ]
}